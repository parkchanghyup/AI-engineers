# 🎇머신러닝

## 1번

**Cross Validation은 무엇이고 어떻게 해야하나요?**

교차검증이란 학습 데이터 셋의 일부를 검증용으로 나눠 모델 학습 후 모델의 성능을 평가할때 사용 하는 것이다. 

- 교차검증의 장점
    - 모든 데이터셋을 훈련에 활용할 수 있다. (k-fold)
    - 데이터 부족으로 인한 underfitting을 방지 할 수 있다.(k-fold)
    - 평과 결과에 따라 조금 더 일반화된 모델을 만들 수 있다.  

- 교차검증의 단점
    - 모델 훈련/평가 시간이 오래 걸린다.

**교차 검증 기법**

- Holdout Cross Validation
    - 일정한 비율의 검증 데이터 셋을 지정하여 사용 하는 것. 
    - Holdout CV의 문제점으로는 `1. 지정된 검증 데이터 셋을 학습 데이터로 사용하지 않는다는 점.` `2.지정된 검증 데이터 셋에 과적합 될 우려가 있음`
    - 위와 같은 이유로 K-Fold CV가 등장함

- K-Fold Cross Validation 
    - 학습 데이터 셋을 k개 fold의 학습 데이터와 검증 데이터로 나눠 반복해서 검증 및 평가 진행

    - K-Fold 순서
        - 학습 데이터 셋을 학습 데이터 셋 + 검증 데이터 셋 으로 사용하기 위해 k개의 폴드로 나눔
        - 첫 번째 폴드를 검증 데이터 셋으로 사용하고 나머지 폴드들을 학습 데이터 셋으로 사용
        - 모델을 학습 한 뒤, 첫 번째 검증 데이터셋 으로 평가.
        - 차례대로 다음 fold를 학습 검증데이터 셋으로 사용 -> 반복
        - 총 k개의 성능 결과가 나오며, 이 k개의 평균을 해당 학습 모델의 최종 성능 이라 함.ㄴ
    - K-fold의 문제점
        - K-Fold의 경우 데이터 셋을 일정한 간격으로 잘라서 사용하는데, 그러다 보니 target 데이터의 비율이 일정하지 않게 테스트 셋에 들어 갈 수 있다.

- Stratified K-Fold Cross Validation 
    - K-fold의 문제점은 target 데이터의 비율을 일정하게 유지 하지 못하는 것을 일정 하게 유지하며, 교차 검증을 진행하는 것




## 2번
---
**회귀 / 분류시 알맞은 metric은 무엇일까요?**

### 회귀 문제  
회귀 문제에서는 실제 값과 모델이 예측하는 값의 차이에 기반을 둔 metric(평가)를 사용 한다. 대표적으로 RSS(단순 오차 제곱합), MSE(평균 제곱 오차), MAE(평균 절대값 오차)가 있다. RSS는 예측값과 실제값의 오차의 제곱합, MSE는 RSS를 데이터의 개수만큼 나눈 값, MAE는 예측값과 실제값의 오차의 절대값의 평균이다.   

<br/>   

MSE의 경우 오차에 제곱이 되기 때문에 **이상치를 잡아내는 데 효과적**이다.  
MAE의 경우 **변동치가 큰 지표와낮은 지표를 같이 예측하는 데 효과적**이다.  
둘 다 가장 간단한 평가 방법으로 직관적인 해석이 가능하지만, 평균을 그대로 이용하기 때문에 **데이터의 크기에 의존한다는 단점**이 있다.  

또한 MSE는 전체 데이터의 크기에 의존하기 때문에 서로 다른 두 모델의 MSE만을 비교해 어떤게 더 좋은 모델인지 판단하기 어렵다는 단점이 있다.  

이를 해결하기 위한 metric으로는 R2(결정계수)가 있다. R2는 `1-(RSS/전체분산) 이다. R2는 **회귀 모델의 설명력을 표현** 하는 지표로써, 그 값이 1에 가까울 수록 높은 성능의 모델이라고 할 수 있다. R2의 식세어 분자인 RSS의 근본은 실제값과 예측값의 차이인데, 그 값이 0에 가까울수록 모델이 잘 예측을 했다는 뜻이므로 R2값이 1에 가까워지게 된다.  


### 분류 문제

분류 문제에서는 어떤 모델이 얼마나 데이터를 클래스에 잘 맞게 분류했느냐를 측정하기 위해서 `Confusion Matrix`라는 것에서 나오는 지표를 사용한다.
Confusion Matrix란 어떤 데이터에 대해 모델이 예측한 클래스와 실제 클래스가 일치하느냐 아니냐를 따지게 된다. 


![confusion_matrix](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbSxu2K%2FbtqGNFA7IBF%2FVEthpSMWOjcoiQ3fnitNQk%2Fimg.png)  

Confusion Matrix에서 직접 적으로 얻을 수 있는 metric으로는 `정확도`, `정밀도`,`재현율`이 있다. 

**정확도**  

정확도는 **(TP+TN) / (TP+TN+FP+FN)** 으로 나타내고 모델이 얼마나 데이터를 잘 분류했느냐, 즉 분류 결과가 얼마나 True로 나왔느냐를 보여준다. 정확도는 일반적으로 분류 모델의 주요 평가 지표로 쓰이지만, 클래스의 개수가 불균형할 경우 신뢰도가 떨어진다는 단점이 있다.  

**정밀도**  

정밀도는 **모델이 Positive라 분류한 데이터 중에서 실제로 Positive인 데이터의 비율**을 나타낸다.  정밀도는 실제로 Negative인 데이터를 Positive라고 판단하면 안 될 때 많이 사용하게 된다. 예를 들어 스팸 메일을 분류할 때, 정상 메일을 스팸 메일로 잘못 분류했을 땐 중요한 메일을 읽지 못할 수도 있다.   
정밀도는 Confusion Matrix에서 **TP/(TP+FP)** 로 구할 수 있다.

**재현율**  
재현율은 **실제 P인 데이터 중에서 모델이 P라고 잘 예측한 데이터의 비율**을 나타낸다. 재현율은 **P인 데이터가 더 중요할 경우**, 즉 실제로 P인 데이터를 N이라고 판단하면 안 될 때 사용하게 된다. 예를 들어 종양의 종류를 판단할 때, 악성 종양(P)를 음성 종양(N)이라고 잘못 분류하면 치명적일 수 있다. 재현율은 데이터의 관점에서 실제로 P인 것이 분모로 들어간다. 따라서 재현율은 **TP/(TP+FN)** 으로 나타낸다.  

**F1-score**  
F1 Score는 정밀도와 재현율을 적절히 혼합해 사용하기 위하여 만들어진 지표로, 정밀도와 재현율의 가중 조회평균 값으로 구성 되어 있다. 원래는 아래와 같은 F-measuer라는 식이고, 여기에 alpha값으로 정확도와 재현율 중 어느 쪽에 더 가중치를 둘것이냐를 결정한다. F1 score는 alpha값이 0.5인 경우 이다.



![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNDxGg%2FbtqGK5fMKGl%2FK5G3CbD4drtT4SDHkW2981%2Fimg.png)





**Reference**
- [Deep Larning with Writing](https://mole-starseeker.tistory.com/30)


## 3번

**알고 있는 metric에 대해 설명해주세요(ex. RMSE, MAE, recall, precision ...)**



**Log-loss**   
분류 모델 평가시 사용하는 평가 지표. 모델이 최종적으로 맞춘 결과만 가지고 성능을 평가할 경우, 얼만큼의 확률로 해당 답을 얻은건지 평가가 불가능하다. 답은 맞췄지만 20%의 확률로 그저 찍은거라면 성능이 좋은 모델이라고 할 수 없다.    
이를 보완하기 위해서는 확률 값을 평가 지표로 사용하면 된다. Log loss는 모델이 예측한 확률 값을 직접적으로 반영하여 평가한다.  

**MSE**  
회귀 모델 평가시 사용하는 평가 지표. 모델의 출력값과 실제 정답의 차이를 제곱하고 이 값들을 모두 합한다. 그리고 미분을 쉽게 하기 위해 n으로 나눠 준다.

**R2**  
회귀 모델 평가시 사용하는 평가 지표.  R2는 `1-(RSS/전체분산) 이다. R2는 **회귀 모델의 설명력을 표현** 하는 지표로써, 그 값이 1에 가까울 수록 높은 성능의 모델이라고 할 수 있다. R2의 식세어 분자인 RSS의 근본은 실제값과 예측값의 차이인데, 그 값이 0에 가까울수록 모델이 잘 예측을 했다는 뜻이므로 R2값이 1에 가까워지게 된다.  


## 4번

**정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?**  

머신러닝 알고리즘은 데이터가 가진 feature(특성)들을 비교하여 데이터의 패턴을 찾는다. 그런데 여기서 데이터 가진 feature의 스케일이 심하게 차이나는 경우 모델이 큰 값에만 민감하게 반응 할 수 있다. 그래서 모든 데이터가 동일한 정도의 중요도로 반영되도록 해주는 게 정규화 이다.

정규화 방법에는 Min-Max 정규화, z-score 정규화가 있다.

- Min-Max Normalization 
    - 모델에 투입 될 모든 데이터 중에서 가장 작은 값을 0, 가장 큰 값을 1로두고, 나머지 값들의 비율을 맞춰 모두 0과 1사이의 값으로 스케일링 해주는 것이다. 따라서 만약 X라는 값을 Min-Max Normalization 시킨다면 X는 `(X-MIN) / (MAX - MIN)`  라는 값을 가지게 될 것이다.  

- Z-Score Normalization 
    - Z-Score 정규화는 `Z = (X-평균) / (표준편차)`를 통해 X라는 값을 Z라는  Z-점수로 바꿀 수 있다. **어떤 데이터가 표준 정규분포에 해당하도록 값을 바꿔준다**라고 보면 될 것 같다.  

    따라서 데이터 X가 평균값과 같다면 0으로 정규화 되겠지만, 평균보다 작으면 음수, 평균보다 크면 양수로 나타난다. 이때 계산되는 음수와 양수의 크기는 그 feature의 표준 편차에 의해 결정된다. 

## 5번

**Local Minima와 Global Minima에 대해 설명해주세요.**

![](https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Extrema_example_original.svg/220px-Extrema_example_original.svg.png)

cost function 함수의 최소값을 취하는 지점을 `Global Minima`라고 한다. 그러나 Cost function이 최소값이 되는 구간을 찾기 위해 경사하강법과 같은 최적화 알고리즘을 사용하다보면 함수가 다른 지점에서 최소값을 찾은것처럼 착각 할 수 있습니다. Cost function이 함수의 최솟값이라고 착각 할 수 있는 지점을 `Local Minima`라고 합니다. 

## 6번

**차원의 저주에 대해 설명해주세요**

차원의 저주란 데이터 학습을 위해 차원이 증가하면서 학습데이터 수가 차원의 수보다 적어져 **성능이 저하되는 현상이다.**  
차원이 증가할 수록 개별 차원 내 학습할 데이터 수가 **적어지는(sparse) 현상 발생**  

차원의 저주를 해결 하기 위해서는 차원을 줄이거나 데이터를 많이 휙득하면 된다.  

## 7번

**dimension reduction기법으로 보통 어떤 것들이 있나요?**  


일반적으로 차원 축소는`feature selection` 과 `feature extraction`으로 나눌 수 있습니다.    
feature selection 은 말 그대로 특정 피처에 종속성이 강한 불필요한 피처는 아예 제거하고, 데이터의 특징을 잘 나타내는 주요 피처만 선택하는 것입니다.  
feature extraction은 기존 피처를 저 차원의 중요 피처로 압축해서 추출하는 것입니다.  
feature extraction의 경우는 `PCA`, `SVD`, `MF` 와 같은 차원 축소 기법들을 활용해 벡터의 차원을 줄여나갈 수 있습니다. 
새롭게 추출된 중요 특성은 기존의 피처가 압축된 것이므로 기존의 피처와는 완전히 다른 값이 됩니다.  



## 8번

**PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 
제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?**

PCA는 분산이 최대가 되도록 하는 축을 찾고, 그 축과 직교하면서 분산이 최대가 되도록 하는 축을 이어 찾아나가는 방식으로 데이터의 차원을 축소합니다.   
이 과정에서 차원이 축소되며, 투영 변환을 반대로 수행하면 데이터의 복원이 가능하고, PCA로 찾은 축들 중, 분산이 적은 축들을 제거함으로서 노이즈를 줄일 수 있습니다.

## 9번

**LSA, LDA, SVD 등의 약자들이 어떤 뜻이고 서로 어떤 관계를 가지는지 설명할 수 있나요?**

LDA 는 토픽모델링(Topic Modeling) 기법 중 하나인 잠재디리클레할당(Latent Dirichlet Allocation, LDA)와 이니셜이 같아서 헷갈리는데 SVD (행렬분해)를 자연어처리 토픽 모델링에 적용한게  잠재디리클레할당(Latent Dirichlet Allocation, LDA)고, 

또 다른 LDA (Linear Discriminant Analysis)는  PCA 에서 확장된 차원 축소 기법입니다. 

 

PCA가 데이터의 차원을 줄이기 위해, 공분산 행렬에서 고유 벡터/고유값을 구하고 

가장 분산이 큰 방향을 가진 고유벡터에 입력데이터를 선형변환하는 컨셉이라면,

 

LDA는 지도 학습(supervised - learning)에서 적용하는 차원 축소 기법이자,

입력 데이터의 클래스(정답) 를 최대한 분리할 수 있는 축을 찾는 기법입니다. 

 

SVD는 정사각행렬이 아닌 m*n 형태의 다양한 행렬을 분해하며, 이를 특이값 분해라 말합니다.

이때 분해되는 행렬은 두 개의 직교 행렬과 하나의 대각행렬이며, 두 직교행렬에 담긴 벡터가 특이벡터입니다. 

## 10번
---
**Markov Chain을 고등학생에게 설명하려면 어떤 방식이 제일 좋을까요?**

Markov Chain에서 가장 중요한 개념은 n회의 상태가 n-1회의 상태에만 영향을 받는다는 가정이다.  
따라서 독립 시행으로 일어나는 정사면체 주사위, 정육면체 주사위, 동전 던지기 게임을 상태(state)로, 해당 게임의 결과에 따라 다른 게임으로 종목을 바꾸는 것을 전이(transition) 생각할 수 있다. 전이 조건을 정하고, 특정한 순서대로 게임을 하게 될 확률을 계산해보는 것으로 설명할 수 있을 것이다.

## 11번
---
**텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?**  

간단하게 TF-IDF로 키워드를 추출하거나 LDA(잠재 디리클레 할당)을 이용하여 주제를 추출 하겠습니다.

## 12번
---
**SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? 거기서 어떤 장점이 발생했나요?**  

SVM은 비선형 분류 모델로 사용하기 위해 저차원 공간의 데이터를 고차원 공간으로 매핑하여 선형 분리가 가능한 데이터로 변환하여 처리한다.



## 13번
---
**다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요.**  
 
1. 결과 도출을 위해 조건부 확률만 계산하면 되므로 매우 빠르고, 메모리를 많이 차지 하지 않는다.
2. 데이터의 특징들이 서로 독립되어 잇을 때 좋은 결과를 얻을 수 있다.
3. 데이터의 양이 적더라도 학습이 용이하다. 

## 14번
---
**Association Rule의 Support, Confidence, Lift에 대해 설명해주세요.**

## 15번
---
**최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?**  
 
**Newton's Method**  
- `방정식 f(x) = 0의 해를 근사적으로 찾을 때 사용하는 방법.` 현재 x값에서 접선을 그리고 접선이 x축과 만나는 지점으로 x를 이동시켜 가면서 점진적으로 해를 찾아가는 방법
- 초기값을 잘 주면 금방 해를 찾을 수 있지만 잘못 주면 시간이 오래 걸리거나 아예 해를 찾지 못할 수 있다.

<br/>

**Gradient Method**
- `f'(x)가 0이 되는 점을 찾는 방법`
- 미분하여 극소점을 찾아가는 방법 (local minimum에 빠질 수도 있다는 것이 문제점)
- 모든 차원과 모든 공간에서 적용이 가능 

<br/>

정리하자면 뉴턴 방법은 해를 찾는 수렴속도가 빠르고 해 근처에서 수렴속도가 급격히 느려지는 문제점이 없다. 반면 gradient descent는 해에 근접할수록 기울기가 0에가까워 지기 때문에 수렵속도가 느려진다. 



## 16번
---
**머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?**  

머신러닝 방법과 전통적 통계 분석 방법은 `사용 하는 목적` 에서 가장 큰 차이가 있다.  

- `머신러닝 방법` : 예측의 성공 확률을 높이는 데에 목적이 있다. 따라서 모델의 신뢰도나 정교한 가정은 상대적으로 덜 중요하며, 오버피팅을 어느정도 감안하더라도 여러 인자를 사용해 예측을 수행한다. **예를 들어 농산물의 가격을 예측 할때, 기온, 습도, 계절 등 최대한의 인자를 모델에 적용해 예측을 수행하며, 어떤 인자가 왜 중요한지는 크게 중요하지 않게 된다.**

- `전통적 통계 분석 방법` : 정해진 분포나 가정을 통해 실패 확률을 줄이는 데에 목적이 있다. 따라서 모형의 복잡성보다는 단순성을 추구하며, 신뢰도가 중요해진다. 추가적으로 파라미터의 해석가능성 또한통게분석 방법에서는 중요하게 다뤄진다. 예컨대, **농산물 가격을 예측할때, 중요 인자를 미리 선택하여 해당 농산물의 가격이 왜 그렇게 측정 됐는지에 대한 설명이 가능해지도록 분석이 이뤄 진다.**


## 17번
---
**인공신경망(deep learning이전의 전통적인)이 가지는 일반적인 문제점은 무엇일까요?**  

딥러닝 이전의 인공신경망은 선형적으로만 회귀, 분류를 수행하기 때문에 층을 깊게 쌓지 못했다. 
때문에 XOR 문제 같은 복잡한 문제를 풀지 못하는 문제점이 있었다. 
이후 시그모이드와 같은 비선형 함수(`활성화 함수`)를 선형 모델에 추가하여 XOR 문제를 해결 하였고, 오차역전파 방법으로 모델을 업데이트 할 수 있게 되면서 레이어를 깊게 쌓은 인공신경망이 발전 하였다.
![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile22.uf.tistory.com%2Fimage%2F99612E4B5C0B73DD3417CA)


## 18번
---
**지금 나오고 있는 deep learning 계열의 혁신의 근간은 무엇이라고 생각하시나요?**  

딥러닝 모델은 엄청난 양의 데이터를 요구합니다.   
아무래도 deep learing 계열 모델의 혁신의 근간은 빅데이터 시대가 도래와 맞물리면서 발전했다고 생각합니다.   
또한 gpu의 발달 ?




## 19번
---
**여러분이 서버를 100대 가지고 있습니다. 이때 인공신경망보다 Random Forest를 써야하는 이유는 뭘까요?**

일반적으로 각 단계별로 의존적인 end-to-end 인공신경망과 달리 Random Forest는 여러개의 독립적인 decision tree를 이용하여   
결과를 투표하는 형식이므로 다수의 서버에서 병렬적인 처리가 용이하다

## 20번
---
**K-means의 대표적 의미론적 단점은 무엇인가요? (계산량 많다는것 말고)**


1. 가중치와 적정 거리에 대한 정의가 필요하다. 관찰 데이터들 사이의 거리를 정의하는 것은 쉽지않고, 각 변수에 대한 가중치를 결정하는 것이 어렵다.
2. 초기 클러스터의 수를 결정하는데에 어려움이 있다. 초기 설정 클러스터의 수가 적합하지 않으면 결과가 좋지 못하다.
3. 모든 데이터를 거리로만 판단하게 됨으로, 사전에 주어진 목적이 없어 해석이 어렵다는 단점도 있다.
4. 이상치에 예민하다

## 21번
---
**L1, L2 정규화에 대해 설명해주세요**

결론부터 이야기하면 `L1 Regularization` 과 `L2 Regularization`은 Overfitting(과적합)을 막기 위해 사용 됩니다.

위 두 개념을 이해하기 위해서는 필요한 개념들을 먼저 설명하고 마지막에 
`L1 Regularization` 과 `L2 Regularization` 설명할 예정입니다. 

순서는 다음과 같고 이 글은 ['light-tree 티스토리'](https://light-tree.tistory.com/125)를 참고하여 작성 되었습니다.

1. Norm
2. L1 Norm과 L2 Norm
3. L1 Loss 와 L2 Loss 

4. L1 Regularization
5. L2 Regularization
6. L1 Regularization, L2 Regularization 의 차이와 선택 기준

### Norm
Norm은 벡터의 크기(혹은 길이)를 측정하는 방법(혹은 함수) 입니다.  두 벡터 사이의 거리를 측정하는 방법이기도 합니다. 
![](https://wikimedia.org/api/rest_v1/media/math/render/svg/53a5615d02f7a03013e22bd4adf055cdbe4a303c)
* 여기서 p는 Norm의 차수를 의미합니다. p = 1이면 L1 Norm이고, p = 2 이면 L2 Norm 입니다.
* N은 해당 벡터의 원소 수 입니다.


### L1 Norm 과 L2 Norm

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FTWoq0%2FbtqyeIS3zkS%2FdM9k9mLKifZvlidw4GftN0%2Fimg.png)

검정색 두 점사이의 L1 Norm은 빨간색, 파란색, 노란색 선으로 표현 될 수 있고, L2 Norm은 오직 초록색 선으로만 표현 될 수 있습니다. L1 Norm은 여러가지 path를 가지지만 L2 Norm은 Unique shortest path를 가집니다.  
예를 들어 p = (1,0), q = (0,0) 일 때 L1 Norm = 1, L2 Norm = 1로 값은 같지만 여전히 Unique shortest path 라고 할 수 있습니다. 

### L1 loss 와 L2 loss

- `L1-loss`는 **타겟값과 예측값의 차를 절대 값으로 구한것** 입니다.  
- `L2-loss`는 **타겟값과 에측값의 차의 제곱으로 구한 것** 입니다.  
    
L2 Loss는 직관적으로 오차의 제곱을 더하기 때문에 Outlier에 더 큰 영향을 받습니다. "L1 Loss가 L2 Loss에 비해 Outlier에 대하여 더 Robust(덜 민감 혹은 둔감)하다."라고 표현 할 수 있습니다.  
Outlier가 적당히 무시되길 원한다면 L1 Loss를 사용하고, Outlier의 등장에 신경써야 하는 경우라면 L2 Loss를 사용하는 것이 좋습니다.   
L1  Loss는 0 인 지점에서 미분이 불가능하다는 단점 또한 가지고 있습니다.

### L1 Regularization 

[](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkClJn%2FbtqLA20hMN9%2FKR9d27A0SkCKkad91TPujk%2Fimg.png)   


L1 Regularization 은 위 수식처럼 표현 할 수 있습니다. L1 Regularization의 개념에서 가장 중요한 것은 cost function에 가중치의 절대값을 더해준다는 것 입니다.  

기존의 cost function에 가중치의 크기가 포함되면서 가중치가 너무 크지 않은 방향으로 학습 되도록 합니다. 이때 λ는 learning rate 같은 상수로 0에 가까울 수록 정규화의 효과는 없어집니다.    

L1 Regularization을 사용하는 Regression model 을 Least Absolute Shrinkage and Selection Operater(Lasso) Regression 이라고 부릅니다.  

### L2 Regularization

[](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fvwncr%2FbtqLzYD49Ef%2F4YyPJV8WMyfxLHPS3nQLq1%2Fimg.png)  

기존의 Cost Function에 가중치의 제곱을 포함하여 더함으로써 L1 Regularization과 마찬가지로 가중치가 너무 크지 않은 방향으로 학습되게 됩니다. 이를 Weight decay 라고도 합니다.  

L2 Regularzation을 사용하는 Regression model을 Ridge Regression 라고 부릅니다.  

### L1 Regularization, L2 Regularization의 차이와 선택 기준

먼저 Regularization의 의미를 되새겨 보면, 가중치 W가 작아지도록 학습한 다는 것은 결국 Local nosie에 영향을 덜 받도록 하겠다는 것이며 이는 Outlier의 영향을 더 적게 받도록 하겠다는 것입니다. 

> a = (0.3, -0.3, 0.4)    
> b = (0.5, -0.5, 0)

벡터 a와 b에 대해서 L1 Norm과 L2 Norm을 계산하면 각각 아래와 같습니다.

> ||a||_1 = |0.3| + |-0.3| + |0.4| = 1  
> ||b||_1 = |0.5| + |-0.5| + |0| = 1
  
> ||a||_2 = 0.583095
> ||b|_2 = 0.707107

L2 Norm은 각각의 벡터에 대해 항상 Unique 한 값을 내지만, L1 Norm은 경우에 따라 특정 Feature(벡터의 요소) 없이도 같은 값을 낼 수 있다는 뜻입니다. 

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FTWoq0%2FbtqyeIS3zkS%2FdM9k9mLKifZvlidw4GftN0%2Fimg.png)  


L1 Norm은 파란색 선 대신 빨간색 선을 사용하여 특정 Feature를 0으로 처리하는 것이 가능하다고 이해할 수 있습니다. 다시 말하자면 **L1 Norm은 Feature selection 이 가능** 하고 이런 특징이 L1 Regularization에 동일하게 적용 될 수 있는 것입니다. 이러한 특징 때문에 L1은 Sparse model(coding)에 적합합니다. L1 Norm의 이러한 특징 때문에 convex optimization에 유용하게 쓰인다고 합니다.



## 22번
---
**XGBoost을 아시나요? 왜 이 모델이 캐글에서 유명할까요?**


Boosting 기법을 이용하여 구현한 알고리즘은 Gradient Boost 가 대표적이고,  
이 알고리즘을 병렬 학습이 지원되도록 구현한 라이브러리가 `XGBoost` 이다.

Regression, Classification 문제를 모두 지원하며, 성능과 자원 효율이 좋아서, 인기 있게 사용되는 알고리즘이다.


여기서 Boosting이 란 무엇이냐면,
여러개의 성능이 높지 않은 모델을 조합해서 사용하는 앙상블 기법중 하나입니다.
성능이 낮은 예측 모형들의 학습 에러에 가중치를 두고, 순차적으로 다음 학습 모델에 반영하여 강한 예측모형을 만듭니다. 아래 그림은 boosting 모델의 학습 예시 입니다.
![](https://jinsu-l.github.io/assets/post_images/image-20191217222322387.png)
xgboost의 장점은 다음 과 같다.  

- 기존 boosting 모델 대비 빠른 수행시간(병렬 처리)

- 과적합 규제 지원(Regularization)

- 분류와 회귀 task 에서 높은 예측 성능

- Early Stopping(조기 종료) 기능 제공.

- 다양한 옵션을 제공해 Customizing이 용이.

- 결측치를 내부적으로 처리 함.



## 23번
---
**앙상블 방법엔 어떤 것들이 있나요?**  

앙상블은 머신러닝에서 여러 모델들을 학습시켜 각 모델의 결과를 합쳐서 더 나은 결과를 내는 방법을 말한다. 앙상블 방법에는 서로 다른 모델들을 학습시켜 결과를 투표하는 Voting, 같은 모델을 다른 Train data로 학습시키는 Bagging(Bootstrap aggregating)과 Pasting, 여러개의 약한 분류기를 결합하여 높은 성능의 모델을 도출하는 Boosting 등이 있다.


## 24번
---
**feature vector란 무엇일까요?**

Feature란 sample을 잘 설명하는 특징이다. Feature를 통해 우리는 특정 sample을 수치화 할 수 있다.  
피쳐들의 집합을 `피쳐 벡터(feature vector)`라고 한다. 

## 25번
---
**좋은 모델의 정의는 무엇일까요?**

좋은모델이란 정확한 기준은 없는거 같다. 어떨때는 높은 성능을 내는 모델이 좋을 수도 있고 어떨때는 성능이 좋지 못하더라도 적은 리소스가 드는 모델이 더 필요할 수있다. 
그래서 상황에 맞게 다르겠지만 굳이 따지자면 적은 리소스로 높은 성능을 내는 모델이 좋은 모델이라고 생각 된다.

## 26번
---
**50개의 작은 의사결정 나무는 큰 의사결정 나무보다 괜찮을까요? 왜 그렇게 생각하나요?**

큰 의사결정나무 하나를 쓰는 것보다 50개의 작은 의사결정나무를 사용하여, 그들의 결과를 취합하는 것이 경우에 따라 더 좋은 성능을 발휘할 수 있을 것이다.-> 앙상블
비선형성이 강한 문제를 해결하는데 있어, 모든 feature를 사용하여 학습한 하나의 큰 의사결정나무보다 feature 일부를 이용하여 학습된 작은 의사결정나무들이 과적합의 정도가 덜할 것이며, 데이터 노이즈에도 강할 것이기 때문이다.

## 27번
---
**스팸 필터에 로지스틱 리그레션을 많이 사용하는 이유는 무엇일까요?**

스팸 필터링 분야에서 좋은 성능을 보이는데다가 해석이 용이하며, 계산 비용도 매우 저렴하기 때문이다.

## 28번
---
OLS(ordinary least squre) regression의 공식은 무엇인가요?

## 29번
---
**ROC 커브에 대해 설명해주실 수 있으신가요?**

ROC 커브는 다양한 threshold에 대한 이진분류기의 성능을 한번에 표시한 것 입니다.  
이진 분류의 성능은 `True Positive Rate`와 `False Positive Rate` 두 가지를 이용해서 표현하게 됩니다.   
ROC 커브를 한 마디로 이야기하면 그래프가 좌상단에 붙어 있을 수록 더 좋은 분류기라고 이해하시면 됩니다.  
![](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-08-05-ROC/pic1.png)  

- True Positive Rate
    - 실제 참값인 데이터를 모델이 잘 분류한 비율을 의미
- False Positive Rate
    - 실제 거짓값인 데이터를 모델이 참 값이라고 잘못 분류한 비율을 의미
