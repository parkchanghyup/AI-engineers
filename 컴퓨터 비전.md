# 컴퓨터 비전

## 딥러닝 발달 이전에 사물을 Detect할 때 자주 사용하던 방법은 무엇인가요?

- haar-like feature(얼굴 검출 알고리즘)
    - 사람얼굴에서 일반적으로 나타나는 명암을 특징으로 활용
    - 검출 속도가 빠르고 높은 검출 성능을 가지지만, 회전된 물체나 다양한 배경과 물체가 복합적으로 이루어진 이미지에서는 오인식 가능성이 높다.
- HOG (Histograms of Oriented Gradients) detector
    - Hog 알고리즘은 보행자 검출을 위해 만든 알고리즘이다.
    - Hog는 영상의 Edge 성분을 이용해 특징을 생성하기 때문에 앞의 haar-like feature와 달리 조명에 영향이 크지 않은 장점이 있다.
    - 이미지를 block 단위로 나누고 block 내부에 위차한 각 셀들의 기울기에 대한 히스토그램 생성
    - 각 셀의 기울기는 인접 픽셀 간 값의 차이에 대한 gradient 값임
    - 위 과정을 모든 블록에 적용하고 이어 붙여 최종 1차원 Hog feature 벡터를 구할 수 있음.
- DPM (Deformable Part Model)
    - 사람 객체의 각 부분에 대한 템플릿을 미리 가지고 있고, 이를 이용해 바운딩 박스 영역마다 템플릿 필터를 적용하여 분류를 수행
    - 앙상블 기법을 사용해 다양한 필터로 분류 결과를 종합
    - 슬라이딩 윈도우로 모든 부분을 일일이 계산하다 보면 바운딩 박스가 많아져 background 검출에 시간이 소모된다는 단점 존재

## Fatser R-CNN의 장점과 단점은 무엇인가요?
![](https://seongkyun.github.io/assets/post_img/papers/2019-01-06-Object_detection/fig7.PNG)
`Fast RCNN`에서는 **전체 이미지에 대한 CNN Feature Extract 결과를 RoI Polling한 후, Selective Search를 통해 Region Proposal을 수행**한다.  
`Faster RCNN`에서는 **Extracted Feature에 Region Proposal Network라고 하는 일종의 CNN을 바로 적용하여 Selective Search에서 발생하는 병목을 줄였습니다.**  
하지만 여전히 마지막 단계에서 NMS(Non-Maximum-Suppression)를 이용하기 때문에 병목은 존재합니다.  
- 장점
    - end-to-end 구조, 빠르고 정확한 학습 가능
    - RPN(Region Proposal Network):RPN을 통해 학습한 후 후보 영역을 생성하고 해당영역에서 물체검출을 수행하기 떄문에 검출 성능을 높이면서도 처리 속도를 빠르게 할 수 있다.
    - 재사용 가능한 특징 추출기 : 학습 과정에서 미리 학습된 특징 추출기를 사용하여, 이를 다른 물체 검출 문제에 쉽게 적용 가능
- 단점
    - 학습 데이터에 대한 의존도가 높다.(대규모 학습 데이터셋 필요)
    - 높은 컴퓨팅 자원 필요
    - Proposla 후보 영역 생성 속도 : RPN을 통해 생성되는  Proposal 후보 영역의 개수가 많아질수록 물체 검출 속도가 느려짐

## dlib은 무엇인가요?

Dlib은 C++ 으로 작성된 크로스 플랫폼 라이브러리이다. 주로 얼굴 검출에 사용된다. HOG(Histogram of Oriented Gradients) Feature를 이용한 방법 혹은 CNN을 통한 얼굴 검출 및 인식 전반을 손쉽게 이용할 수 있다.

# **YOLO의 특징**

yolo(You only Look Once)는 객체 검출(objectdetection) 모델이다. 

### YOLOv1

- 이미지 전체를 그리드로 나누어 한 번에 모든 객체를 예측하는 end-to-end모델.
- 당시 출시된 다른 모델 대비 빠른 속도와 높은정확도를 가지며 학습이 쉽다는 장점이 있음

### YOLOv2

- Darknet을 bakc-born 으로 개발된 모델
- residual connection 과 batch normalization을 도입하여 정확도를 개선
- 다양한 크기의 객체를 검출할 수 있도록 Anchor Box를 도입한 모델

### YOLOv3

- YOLOv2에서 더 많은 Anchor Box를 사용하여 객체 검출 정확도를 높임
- 또한 Feature Pyramid Network와 SPPnet을 도입하여 더욱 정교한 검출이 가능해짐
- 다양한 크기의 객체를 검출 할 수 있는 YOLOv2의 장점을 유지

### YOLOv4

- CSPNet과 Spatial Attention Module 등의 기술을 적용하여 정확도 개선

### YOLOv5

- PyTorch 기반으로 개발된 모델
- 다양한 크기의 개체 검출 가능
- Label smoothing 등의 기술을 도입하여 일반화 성능 개선

### YOLOv6

- YOLOX와 유사한 빠른 속도와 높은 정확도를 가진 모델

### YOLOv7

- inference cost를 증가시키지 않고도 detection 정확도를 크게 향상시킬 수 있도록 trainable bag-of-freebies 사용
- parameters와 computation을 효과적으로 활용할 수 있는 real-time object detector를 위한 'extend' 및 'compound scaling' 방법을 사용

# **Object Detection 알고리즘의 종류와 특징**

### R-CNN

- selective search 기반 region proposal 알고리즘을 사용하여 후보 영역을 추출하고, 각 후보 영역에 대해 CNN(Convolutional Neural Network)를 사용하여 분류 및 위치 정보 추정
- 성능은 좋지만 속도는 느림

### Fater R-CNN

- RPN(Region Proposal Network)를 사용하여 후보 영역을 추출하고 후보 영역에 대해 CNN 을 사용하여 분류 및 위치 정보를 추정하는 방식
- R-CNN 계열에 비해 속도가 빠르고 성능도 우수하지만 학습이 오래 걸림

### Mask R-CNN

- Faster R-CNN을 기반으로 객체 인식과 함께 객체의 segmetation(픽셀 단위 분할)도 수행
- 다양한 응용 분야아세 활용 가능하지만, 다른 알고리즘 대비 속도가 느리고, 많은 계산 리소스가 필요.

### YOLO 계열

- 이미지 전체를 그리드로 나누어 한 번에 모든 객체를 예측하는 end-to-end방식
- 다른 알고리즘 대비 빠른 속도와 정확도를 가지며 학습이 쉬움

### SSD 계열

- Convolutional feature map에서 다양한 크기의 anchor box를 사용하여 객체를 검출하는 방식.
- 다른 알고리즘 대비 속도는 빠르지만 작은 객체 검출은 어려움.

### CenterNet

- 객체의 중심점을 검출하고, 크기와 방향을 추정하는 방식
- 다른 알고리즘 대비 높은 정확도를 보이며 속도도 빠름

# **Residual Network는 왜 잘될까요? Ensemble과 관련되어 있을까요?**

관계 없고 ResNet은 gradient vanishing 문제를 해결하여 더욱 깊은 네트워크를 구성할 수 있게 도와주는 기법이다.

## CAM(Class Activation Map)은 무엇인가요?

- **"모델이 어떤 곳을 보고 어떤 클래스임을 짐작하고 있는지" 확인할 수 있는 지도**
- 설명할 수 있는 AI의 기본이 될 수 있다.

## Localization은 무엇일까요?

## 자율주행 자동차의 원리는 무엇일까요?

### 컴퓨터 비전 알고리즘

- 카메라, 레이더, 라이드 당의 센서를 이용해 주행환경을 인식하고 이를 이미지나 포인트 클라우드 형태로 변환하여 처리한다.

### 센서 퓨전 알고리즘

- 다양한 종류의 센서들이 수집한 정보를 효과적으로 통합하여 주행환경을 인식하고 장애물 및 교통 상황을 파악한다.

### 차량 제어 알고리즘

- 주행환경을 기반으로 차량의 속도, 방향, 가속도 등을 결정하고 제어한다.

## Semantic Segmentation은 무엇인가요?

- 이미지를 픽셀 단위로 분류하여 각 픽셀이 어떤 클래스에 속하는지 판별하는 기술
- 이를 통해 이미지 내의 객체나 영역을 정확하게 분할하고, 각각의 의미를 파악할 수 있다.
- 자율주행 차량, 의료영상, 보안감시 등 다양한 분야에서 활용
- 주요한 알고리즘으로는 Fully Convolutional Network(FCN), U-Net, Mask R-CNN가 있음.

## Visual Q&A는 무엇인가요?

- 이미지와 관련된 질문에 대해 자연어 처리 기술을 이용하여 답변하는 기술
- 이미지에서 특징을 추출하고, 자연어 처리 모델을 통해 질문을 이해하고 답변을 생성
- 현재 open ai의 [visual chat-gpt](https://github.com/microsoft/TaskMatrix)가 가장 대중화된 모델이다.

## Image Captioning은 무엇인가요?

- image to text 기술.
- 주어진 이미지에서 특징을 추출하고 이를 바탕으로 자연어 처리 모델을 이용해 이미지의 내용을 문장으로 표현한다.

## Fully Connected Layer의 기능은 무엇인가요?

- 입력 데이터와 가중치를 행렬곱하여 출력을 계산함
- 입력 데이터에 대한 비선형 변환을 수행하고, 인공신경망의 출력을 만든다.

## Neural Style은 어떻게 진행될까요?

- style 이미지와 content 이미지를 결합하여 새로운 이미지를 생성하는 기술
- 이미지에서 각각 특징을 추출하여 새로운 이미지를 생성한다.

## CNN이 MLP보다 좋은 이유는?

1. CNN은 이미지 음성등과 같은 다차원 데이터 처리에 적합하다. 이미지는 픽셀로 이루어진 2D 데이터이며, 음성은 시간에 따른 신호의 1D 데이터입니다. 이와 같은 다차원 데이터 처리는 MLP에서는 어렵다.
2. CNN은 가중치 공유(Weight Sharing)를 통해 인공신경망의 파라미터 수를 크게 줄일 수 있다 → 학습 시간 단축 및 효과적인 이미지 처리 가능 

## 어떤 CNN의 파라미터 개수를 계산해 본다면?

### 가정

- 입력 이미지 크기 : 224 x 224
- Convolutional Layer 2개
- 각각의 필터 크기 3x3
- 두 개의 Convolutional Layer 사이에 Max Pooling Layer가 있고, Fully Connected Layer가 하나 있다고 가정

### 계산

- 첫 번째 Convlutional Layer의 필터 개수가 64개라면, 해당 Layer의 파라미터 개수는 (3x3x3)x64 = 1,729 * 64 = 110,592개
- 두 번째 Convolutional Layer에서는 입력 채널이 64개 이고 출력 채널이 128이므로 해당 Layer의 파라미터 개수는 (3x3x64)x128 = 73,728 x 128 = 9,437,184개
- Max Pooling Layer의 경우 파라미터를 가지지 않으며, Fully Connected Layer는 1,0438,576개
- 최종 적으로 11,548,352개의 파라미터를 사용함.

## 시퀀스 데이터에 CNN을 적용하는 것이 가능할까?

시퀀스 데이터를 각각의 단어나 타입스템을 입력 이미지의 픽셀값으로 간주하여 CNN을 사용할 수 있다.
