# 🎇머신러닝

## 1번
**Cross Validation은 무엇이고 어떻게 해야하나요?**

교차검증이란 학습 데이터 셋의 일부를 검증용으로 나눠 모델 학습 후 모델의 성능을 평가할때 사용 하는 것이다. 

- 교차검증의 장점
    - 모든 데이터셋을 훈련에 활용할 수 있다. (k-fold)
    - 데이터 부족으로 인한 underfitting을 방지 할 수 있다.(k-fold)
    - 평과 결과에 따라 조금 더 일반화된 모델을 만들 수 있다.  

- 교차검증의 단점
    - 모델 훈련/평가 시간이 오래 걸린다.

**교차 검증 기법**

- Holdout Cross Validation
    - 일정한 비율의 검증 데이터 셋을 지정하여 사용 하는 것. 
    - Holdout CV의 문제점으로는 `1. 지정된 검증 데이터 셋을 학습 데이터로 사용하지 않는다는 점.` `2.지정된 검증 데이터 셋에 과적합 될 우려가 있음`
    - 위와 같은 이유로 K-Fold CV가 등장함

- K-Fold Cross Validation 
    - 학습 데이터 셋을 k개 fold의 학습 데이터와 검증 데이터로 나눠 반복해서 검증 및 평가 진행

    - K-Fold 순서
        - 학습 데이터 셋을 학습 데이터 셋 + 검증 데이터 셋 으로 사용하기 위해 k개의 폴드로 나눔
        - 첫 번째 폴드를 검증 데이터 셋으로 사용하고 나머지 폴드들을 학습 데이터 셋으로 사용
        - 모델을 학습 한 뒤, 첫 번째 검증 데이터셋 으로 평가.
        - 차례대로 다음 fold를 학습 검증데이터 셋으로 사용 -> 반복
        - 총 k개의 성능 결과가 나오며, 이 k개의 평균을 해당 학습 모델의 최종 성능 이라 함.ㄴ
    - K-fold의 문제점
        - K-Fold의 경우 데이터 셋을 일정한 간격으로 잘라서 사용하는데, 그러다 보니 target 데이터의 비율이 일정하지 않게 테스트 셋에 들어 갈 수 있다.

- Stratified K-Fold Cross Validation 
    - K-fold의 문제점은 target 데이터의 비율을 일정하게 유지 하지 못하는 것을 일정 하게 유지하며, 교차 검증을 진행하는 것




## 2번
회귀 / 분류시 알맞은 metric은 무엇일까요?

### 회귀 문제  
회귀 문제에서는 실제 값과 모델이 예측하는 값의 차이에 기반을 둔 metric(평가)를 사용 한다. 대표적으로 RSS(단순 오차 제곱합), MSE(평균 제곱 오차), MAE(평균 절대값 오차)가 있다. RSS는 예측값과 실제값의 오차의 제곱합, MSE는 RSS를 데이터의 개수만큼 나눈 값, MAE는 예측값과 실제값의 오차의 절대값의 평균이다.   

<br/>   

MSE의 경우 오차에 제곱이 되기 때문에 **이상치를 잡아내는 데 효과적**이다.  
MAE의 경우 **변동치가 큰 지표와낮은 지표를 같이 예측하는 데 효과적**이다.  
둘 다 가장 간단한 평가 방법으로 직관적인 해석이 가능하지만, 평균을 그대로 이용하기 때문에 **데이터의 크기에 의존한다는 단점**이 있다.  

또한 MSE는 전체 데이터의 크기에 의존하기 때문에 서로 다른 두 모델의 MSE만을 비교해 어떤게 더 좋은 모델인지 판단하기 어렵다는 단점이 있다.  

이를 해결하기 위한 metric으로는 R2(결정계수)가 있다. R2는 `1-(RSS/전체분산) 이다. R2는 **회귀 모델의 설명력을 표현** 하는 지표로써, 그 값이 1에 가까울 수록 높은 성능의 모델이라고 할 수 있다. R2의 식세어 분자인 RSS의 근본은 실제값과 예측값의 차이인데, 그 값이 0에 가까울수록 모델이 잘 예측을 했다는 뜻이므로 R2값이 1에 가까워지게 된다.  


### 분류 문제

분류 문제에서는 어떤 모델이 얼마나 데이터를 클래스에 잘 맞게 분류했느냐를 측정하기 위해서 `Confusion Matrix`라는 것에서 나오는 지표를 사용한다.
Confusion Matrix란 어떤 데이터에 대해 모델이 예측한 클래스와 실제 클래스가 일치하느냐 아니냐를 따지게 된다. 


![confusion_matrix](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbSxu2K%2FbtqGNFA7IBF%2FVEthpSMWOjcoiQ3fnitNQk%2Fimg.png)  

Confusion Matrix에서 직접 적으로 얻을 수 있는 metric으로는 `정확도`, `정밀도`,`재현율`이 있다. 

**정확도**  

정확도는 **(TP+TN) / (TP+TN+FP+FN)**으로 나타내고 모델이 얼마나 데이터를 잘 분류했느냐, 즉 분류 결과가 얼마나 True로 나왔느냐를 보여준다. 정확도는 일반적으로 분류 모델의 주요 평가 지표로 쓰이지만, 클래스의 개수가 불균형할 경우 신뢰도가 떨어진다는 단점이 있다.  

**정밀도**  
정밀도는 **모델이 Positive라 분류한 데이터 중에서 실제로 Positive인 데이터의 비율**을 나타낸다.  정밀도는 실제로 Negative인 데이터를 Positive라고 판단하면 안 될 때 많이 사용하게 된다. 예를 들어 스팸 메일을 분류할 때, 정상 메일을 스팸 메일로 잘못 분류했을 땐 중요한 메일을 읽지 못할 수도 있다.   
정밀도는 Confusion Matrix에서 **TP/(TP+FP)**로 구할 수 있다.

**재현율**  
재현율은 **실제 P인 데이터 중에서 모델이 P라고 잘 예측한 데이터의 비율**을 나타낸다. 재현율은 **P인 데이터가 더 중요할 경우**, 즉 실제로 P인 데이터를 N이라고 판단하면 안 될 때 사용하게 된다. 예를 들어 종양의 종류를 판단할 때, 악성 종양(P)를 음성 종양(N)이라고 잘못 분류하면 치명적일 수 있다. 재현율은 데이터의 관점에서 실제로 P인 것이 분모로 들어간다. 따라서 재현율은 **TP/(TP+FN)**으로 나타낸다.  

**F1-score**
F1 Score는 정밀도와 재현율을 적절히 혼합해 사용하기 위하여 만들어진 지표로, 정밀도와 재현율의 가중 조회평균 값으로 구성 되어 있다. 원래는 아래와 같은 F-measuer라는 식이고, 여기에 alpha값으로 정확도와 재현율 중 어느 쪽에 더 가중치를 둘것이냐를 결정한다. F1 score는 alpha값이 0.5인 경우 이다.



![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNDxGg%2FbtqGK5fMKGl%2FK5G3CbD4drtT4SDHkW2981%2Fimg.png)





**Reference**
- [Deep Larning with Writing](https://mole-starseeker.tistory.com/30)


## 3번
**알고 있는 metric에 대해 설명해주세요(ex. RMSE, MAE, recall, precision ...)**

**정확도**  

정확도는 **(TP+TN) / (TP+TN+FP+FN)**으로 나타내고 모델이 얼마나 데이터를 잘 분류했느냐, 즉 분류 결과가 얼마나 True로 나왔느냐를 보여준다. 정확도는 일반적으로 분류 모델의 주요 평가 지표로 쓰이지만, 클래스의 개수가 불균형할 경우 신뢰도가 떨어진다는 단점이 있다.  

**정밀도**  
정밀도는 **모델이 Positive라 분류한 데이터 중에서 실제로 Positive인 데이터의 비율**을 나타낸다.  정밀도는 실제로 Negative인 데이터를 Positive라고 판단하면 안 될 때 많이 사용하게 된다. 예를 들어 스팸 메일을 분류할 때, 정상 메일을 스팸 메일로 잘못 분류했을 땐 중요한 메일을 읽지 못할 수도 있다.   
정밀도는 Confusion Matrix에서 **TP/(TP+FP)**로 구할 수 있다.

**재현율**  
재현율은 **실제 P인 데이터 중에서 모델이 P라고 잘 예측한 데이터의 비율**을 나타낸다. 재현율은 **P인 데이터가 더 중요할 경우**, 즉 실제로 P인 데이터를 N이라고 판단하면 안 될 때 사용하게 된다. 예를 들어 종양의 종류를 판단할 때, 악성 종양(P)를 음성 종양(N)이라고 잘못 분류하면 치명적일 수 있다. 재현율은 데이터의 관점에서 실제로 P인 것이 분모로 들어간다. 따라서 재현율은 **TP/(TP+FN)**으로 나타낸다.  

**F1-score**
F1 Score는 정밀도와 재현율을 적절히 혼합해 사용하기 위하여 만들어진 지표로, 정밀도와 재현율의 가중 조회평균 값으로 구성 되어 있다. 원래는 아래와 같은 F-measuer라는 식이고, 여기에 alpha값으로 정확도와 재현율 중 어느 쪽에 더 가중치를 둘것이냐를 결정한다. F1 score는 alpha값이 0.5인 경우 이다.

**Log-loss** 
분류 모델 평가시 사용하는 평가 지표. 모델이 최종적으로 맞춘 결과만 가지고 성능을 평가할 경우, 얼만큼의 확률로 해당 답을 얻은건지 평가가 불가능하다. 답은 맞췄지만 20%의 확률로 그저 찍은거라면 성능이 좋은 모델이라고 할 수 없다.    
이를 보완하기 위해서는 확률 값을 평가 지표로 사용하면 된다. Log loss는 모델이 예측한 확률 값을 직접적으로 반영하여 평가한다.  

**MSE**
회귀 모델 평가시 사용하는 평가 지표. 모델의 출력값과 실제 정답의 차이를 제곱하고 이 값들을 모두 합한다. 그리고 미분을 쉽게 하기 위해 n으로 나눠 준다.

**R2**
회귀 모델 평가시 사용하는 평가 지표.  R2는 `1-(RSS/전체분산) 이다. R2는 **회귀 모델의 설명력을 표현** 하는 지표로써, 그 값이 1에 가까울 수록 높은 성능의 모델이라고 할 수 있다. R2의 식세어 분자인 RSS의 근본은 실제값과 예측값의 차이인데, 그 값이 0에 가까울수록 모델이 잘 예측을 했다는 뜻이므로 R2값이 1에 가까워지게 된다.  


## 4번

**정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?**  

머신러닝 알고리즘은 데이터가 가진 feature(특성)들을 비교하여 데이터의 패턴을 찾는다. 그런데 여기서 데이터 가진 feature의 스케일이 심하게 차이나는 경우 모델이 큰 값에만 민감하게 반응 할 수 있다. 그래서 모든 데이터가 동일한 정도의 중요도로 반영되도록 해주는 게 정규화 이다.

정규화 방법에는 Min-Max 정규화, z-score 정규화가 있다.

- Min-Max Normalization 
    - 모델에 투입 될 모든 데이터 중에서 가장 작은 값을 0, 가장 큰 값을 1로두고, 나머지 값들의 비율을 맞춰 모두 0과 1사이의 값으로 스케일링 해주는 것이다. 따라서 만약 X라는 값을 Min-Max Normalization 시킨다면 X는 `(X-MIN) / (MAX - MIN)`  라는 값을 가지게 될 것이다.  

- Z-Score Normalization 
    - Z-Score 정규화는 `Z = (X-평균) / (표준편차)`를 통해 X라는 값을 Z라는  Z-점수로 바꿀 수 있다. **어떤 데이터가 표준 정규분포에 해당하도록 값을 바꿔준다**라고 보면 될 것 같다.  

    따라서 데이터 X가 평균ㅏㅄ과 같다면 0으로 정규화 되겠지만, 평균보다 작으면 음수, 평균보다 크면 양수로 나타난다. 이때 계산되는 음수와 양수의 크기는 그 feature의 표준 편차에 의해 결정된다. 
## 5번

**Local Minima와 Global Minima에 대해 설명해주세요.**

![](https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Extrema_example_original.svg/220px-Extrema_example_original.svg.png)

cost function 함수의 최소값을 취하는 지점을 `Global Minima`라고 한다. 그러나 Cost function이 최소값이 되는 구간을 찾기 위해 경사하강법과 같은 최적화 알고리즘을 사용하다보면 함수가 다른 지점에서 최소값을 찾은것처럼 착각 할 수 있습니다. Cost function이 함수의 최솟값이라고 착각 할 수 있는 지점을 `Locla Minima`라고 합니다. 

## 6번

**차원의 저주에 대해 설명해주세요**

차원의 저주란 데이터 학습을 위해 차원이 증가하면서 학습데이터 수가 차원의 수보다 적어져 **성능이 저하되는 현상이다.**  
차원이 증가할 수록 개별 차원 내 학습할 데이터 수가 **적어지는(sparse) 현상 발생**  

차원의 저주를 해결 하기 위해서는 차원을 줄이거나 데이터를 많이 휙득하면 된다.  

## 7번

dimension reduction기법으로 보통 어떤 것들이 있나요?

## 8번
PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 
제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?

## 9번
LSA, LDA, SVD 등의 약자들이 어떤 뜻이고 서로 어떤 관계를 가지는지 설명할 수 있나요?

## 10번
Markov Chain을 고등학생에게 설명하려면 어떤 방식이 제일 좋을까요?

## 11번
텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?

## 12번
SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? 거기서 어떤 장점이 발생했나요?

## 13번
다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요.

## 14번
Association Rule의 Support, Confidence, Lift에 대해 설명해주세요.

## 15번
최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?

## 16번
머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?

## 17번
인공신경망(deep learning이전의 전통적인)이 가지는 일반적인 문제점은 무엇일까요?

## 18번
지금 나오고 있는 deep learning 계열의 혁신의 근간은 무엇이라고 생각하시나요?
ROC 커브에 대해 설명해주실 수 있으신가요?

## 19번
여러분이 서버를 100대 가지고 있습니다. 이때 인공신경망보다 Random Forest를 써야하는 이유는 뭘까요?

## 20번
K-means의 대표적 의미론적 단점은 무엇인가요? (계산량 많다는것 말고)

## 21번
L1, L2 정규화에 대해 설명해주세요

## 22번

XGBoost을 아시나요? 왜 이 모델이 캐글에서 유명할까요?

## 23번
앙상블 방법엔 어떤 것들이 있나요?

## 24번
feature vector란 무엇일까요?

## 25번
좋은 모델의 정의는 무엇일까요?

## 26번
50개의 작은 의사결정 나무는 큰 의사결정 나무보다 괜찮을까요? 왜 그렇게 생각하나요?

## 27번
스팸 필터에 로지스틱 리그레션을 많이 사용하는 이유는 무엇일까요?

## 28번
OLS(ordinary least squre) regression의 공식은 무엇인가요?