# 🎇머신러닝

## 1번
**Cross Validation은 무엇이고 어떻게 해야하나요?**

교차검증이란 학습 데이터 셋의 일부를 검증용으로 나눠 모델 학습 후 모델의 성능을 평가할때 사용 하는 것이다. 

- 교차검증의 장점
    - 모든 데이터셋을 훈련에 활용할 수 있다. (k-fold)
    - 데이터 부족으로 인한 underfitting을 방지 할 수 있다.(k-fold)
    - 평과 결과에 따라 조금 더 일반화된 모델을 만들 수 있다.  

- 교차검증의 단점
    - 모델 훈련/평가 시간이 오래 걸린다.

**교차 검증 기법**

- Holdout Cross Validation
    - 일정한 비율의 검증 데이터 셋을 지정하여 사용 하는 것. 
    - Holdout CV의 문제점으로는 `1. 지정된 검증 데이터 셋을 학습 데이터로 사용하지 않는다는 점.` `2.지정된 검증 데이터 셋에 과적합 될 우려가 있음`
    - 위와 같은 이유로 K-Fold CV가 등장함

- K-Fold Cross Validation 
    - 학습 데이터 셋을 k개 fold의 학습 데이터와 검증 데이터로 나눠 반복해서 검증 및 평가 진행

    - K-Fold 순서
        - 학습 데이터 셋을 학습 데이터 셋 + 검증 데이터 셋 으로 사용하기 위해 k개의 폴드로 나눔
        - 첫 번째 폴드를 검증 데이터 셋으로 사용하고 나머지 폴드들을 학습 데이터 셋으로 사용
        - 모델을 학습 한 뒤, 첫 번째 검증 데이터셋 으로 평가.
        - 차례대로 다음 fold를 학습 검증데이터 셋으로 사용 -> 반복
        - 총 k개의 성능 결과가 나오며, 이 k개의 평균을 해당 학습 모델의 최종 성능 이라 함.ㄴ
    - K-fold의 문제점
        - K-Fold의 경우 데이터 셋을 일정한 간격으로 잘라서 사용하는데, 그러다 보니 target 데이터의 비율이 일정하지 않게 테스트 셋에 들어 갈 수 있다.

- Stratified K-Fold Cross Validation 
    - K-fold의 문제점은 target 데이터의 비율을 일정하게 유지 하지 못하는 것을 일정 하게 유지하며, 교차 검증을 진행하는 것




## 2번
회귀 / 분류시 알맞은 metric은 무엇일까요?

### 회귀 문제  
회귀 문제에서는 실제 값과 모델이 예측하는 값의 차이에 기반을 둔 metric(평가)를 사용 한다. 대표적으로 RSS(단순 오차 제곱합), MSE(평균 제곱 오차), MAE(평균 절대값 오차)가 있다. RSS는 예측값과 실제값의 오차의 제곱합, MSE는 RSS를 데이터의 개수만큼 나눈 값, MAE는 예측값과 실제값의 오차의 절대값의 평균이다.   

<br/>   

MSE의 경우 오차에 제곱이 되기 때문에 **이상치를 잡아내는 데 효과적**이다.  
MAE의 경우 **변동치가 큰 지표와낮은 지표를 같이 예측하는 데 효과적**이다.  
둘 다 가장 간단한 평가 방법으로 직관적인 해석이 가능하지만, 평균을 그대로 이용하기 때문에 **데이터의 크기에 의존한다는 단점**이 있다.  

또한 MSE는 전체 데이터의 크기에 의존하기 때문에 서로 다른 두 모델의 MSE만을 비교해 어떤게 더 좋은 모델인지 판단하기 어렵다는 단점이 있다.  

이를 해결하기 위한 metric으로는 R2(결정계수)가 있다. R2는 `1-(RSS/전체분산) 이다. R2는 **회귀 모델의 설명력을 표현** 하는 지표로써, 그 값이 1에 가까울 수록 높은 성능의 모델이라고 할 수 있다. R2의 식세어 분자인 RSS의 근본은 실제값과 예측값의 차이인데, 그 값이 0에 가까울수록 모델이 잘 예측을 했다는 뜻이므로 R2값이 1에 가까워지게 된다.  


### 분류 문제

분류 문제에서는 어떤 모델이 얼마나 데이터를 클래스에 잘 맞게 분류했느냐를 측정하기 위해서 `Confusion Matrix`라는 것에서 나오는 지표를 사용한다.
Confusion Matrix란 어떤 데이터에 대해 모델이 예측한 클래스와 실제 클래스가 일치하느냐 아니냐를 따지게 된다. 


![confusion_matrix](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbSxu2K%2FbtqGNFA7IBF%2FVEthpSMWOjcoiQ3fnitNQk%2Fimg.png)  

Confusion Matrix에서 직접 적으로 얻을 수 있는 metric으로는 `정확도`, `정밀도`,`재현율`이 있다. 

**정확도**  

정확도는 **(TP+TN) / (TP+TN+FP+FN)**으로 나타내고 모델이 얼마나 데이터를 잘 분류했느냐, 즉 분류 결과가 얼마나 True로 나왔느냐를 보여준다. 정확도는 일반적으로 분류 모델의 주요 평가 지표로 쓰이지만, 클래스의 개수가 불균형할 경우 신뢰도가 떨어진다는 단점이 있다.  

**정밀도**  
정밀도는 **모델이 Positive라 분류한 데이터 중에서 실제로 Positive인 데이터의 비율**을 나타낸다.  정밀도는 실제로 Negative인 데이터를 Positive라고 판단하면 안 될 때 많이 사용하게 된다. 예를 들어 스팸 메일을 분류할 때, 정상 메일을 스팸 메일로 잘못 분류했을 땐 중요한 메일을 읽지 못할 수도 있다.   
정밀도는 Confusion Matrix에서 **TP/(TP+FP)**로 구할 수 있다.

**재현율**  
재현율은 **실제 P인 데이터 중에서 모델이 P라고 잘 예측한 데이터의 비율**을 나타낸다. 재현율은 **P인 데이터가 더 중요할 경우**, 즉 실제로 P인 데이터를 N이라고 판단하면 안 될 때 사용하게 된다. 예를 들어 종양의 종류를 판단할 때, 악성 종양(P)를 음성 종양(N)이라고 잘못 분류하면 치명적일 수 있다. 재현율은 데이터의 관점에서 실제로 P인 것이 분모로 들어간다. 따라서 재현율은 **TP/(TP+FN)**으로 나타낸다.  

**F1-score**
F1 Score는 정밀도와 재현율을 적절히 혼합해 사용하기 위하여 만들어진 지표로, 정밀도와 재현율의 가중 조회평균 값으로 구성 되어 있다. 원래는 아래와 같은 F-measuer라는 식이고, 여기에 alpha값으로 정확도와 재현율 중 어느 쪽에 더 가중치를 둘것이냐를 결정한다. F1 score는 alpha값이 0.5인 경우 이다.



![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNDxGg%2FbtqGK5fMKGl%2FK5G3CbD4drtT4SDHkW2981%2Fimg.png)





**Reference**
- [Deep Larning with Writing](https://mole-starseeker.tistory.com/30)


## 3번
**알고 있는 metric에 대해 설명해주세요(ex. RMSE, MAE, recall, precision ...)**

**정확도**  

정확도는 **(TP+TN) / (TP+TN+FP+FN)**으로 나타내고 모델이 얼마나 데이터를 잘 분류했느냐, 즉 분류 결과가 얼마나 True로 나왔느냐를 보여준다. 정확도는 일반적으로 분류 모델의 주요 평가 지표로 쓰이지만, 클래스의 개수가 불균형할 경우 신뢰도가 떨어진다는 단점이 있다.  

**정밀도**  
정밀도는 **모델이 Positive라 분류한 데이터 중에서 실제로 Positive인 데이터의 비율**을 나타낸다.  정밀도는 실제로 Negative인 데이터를 Positive라고 판단하면 안 될 때 많이 사용하게 된다. 예를 들어 스팸 메일을 분류할 때, 정상 메일을 스팸 메일로 잘못 분류했을 땐 중요한 메일을 읽지 못할 수도 있다.   
정밀도는 Confusion Matrix에서 **TP/(TP+FP)**로 구할 수 있다.

**재현율**  
재현율은 **실제 P인 데이터 중에서 모델이 P라고 잘 예측한 데이터의 비율**을 나타낸다. 재현율은 **P인 데이터가 더 중요할 경우**, 즉 실제로 P인 데이터를 N이라고 판단하면 안 될 때 사용하게 된다. 예를 들어 종양의 종류를 판단할 때, 악성 종양(P)를 음성 종양(N)이라고 잘못 분류하면 치명적일 수 있다. 재현율은 데이터의 관점에서 실제로 P인 것이 분모로 들어간다. 따라서 재현율은 **TP/(TP+FN)**으로 나타낸다.  

**F1-score**
F1 Score는 정밀도와 재현율을 적절히 혼합해 사용하기 위하여 만들어진 지표로, 정밀도와 재현율의 가중 조회평균 값으로 구성 되어 있다. 원래는 아래와 같은 F-measuer라는 식이고, 여기에 alpha값으로 정확도와 재현율 중 어느 쪽에 더 가중치를 둘것이냐를 결정한다. F1 score는 alpha값이 0.5인 경우 이다.

**Log-loss** 
분류 모델 평가시 사용하는 평가 지표. 모델이 최종적으로 맞춘 결과만 가지고 성능을 평가할 경우, 얼만큼의 확률로 해당 답을 얻은건지 평가가 불가능하다. 답은 맞췄지만 20%의 확률로 그저 찍은거라면 성능이 좋은 모델이라고 할 수 없다.    
이를 보완하기 위해서는 확률 값을 평가 지표로 사용하면 된다. Log loss는 모델이 예측한 확률 값을 직접적으로 반영하여 평가한다.  

**MSE**
회귀 모델 평가시 사용하는 평가 지표. 모델의 출력값과 실제 정답의 차이를 제곱하고 이 값들을 모두 합한다. 그리고 미분을 쉽게 하기 위해 n으로 나눠 준다.

**R2**
회귀 모델 평가시 사용하는 평가 지표.  R2는 `1-(RSS/전체분산) 이다. R2는 **회귀 모델의 설명력을 표현** 하는 지표로써, 그 값이 1에 가까울 수록 높은 성능의 모델이라고 할 수 있다. R2의 식세어 분자인 RSS의 근본은 실제값과 예측값의 차이인데, 그 값이 0에 가까울수록 모델이 잘 예측을 했다는 뜻이므로 R2값이 1에 가까워지게 된다.  


## 4번

**정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?**  

머신러닝 알고리즘은 데이터가 가진 feature(특성)들을 비교하여 데이터의 패턴을 찾는다. 그런데 여기서 데이터 가진 feature의 스케일이 심하게 차이나는 경우 모델이 큰 값에만 민감하게 반응 할 수 있다. 그래서 모든 데이터가 동일한 정도의 중요도로 반영되도록 해주는 게 정규화 이다.

정규화 방법에는 Min-Max 정규화, z-score 정규화가 있다.

- Min-Max Normalization 
    - 모델에 투입 될 모든 데이터 중에서 가장 작은 값을 0, 가장 큰 값을 1로두고, 나머지 값들의 비율을 맞춰 모두 0과 1사이의 값으로 스케일링 해주는 것이다. 따라서 만약 X라는 값을 Min-Max Normalization 시킨다면 X는 `(X-MIN) / (MAX - MIN)`  라는 값을 가지게 될 것이다.  

- Z-Score Normalization 
    - Z-Score 정규화는 `Z = (X-평균) / (표준편차)`를 통해 X라는 값을 Z라는  Z-점수로 바꿀 수 있다. **어떤 데이터가 표준 정규분포에 해당하도록 값을 바꿔준다**라고 보면 될 것 같다.  

    따라서 데이터 X가 평균ㅏㅄ과 같다면 0으로 정규화 되겠지만, 평균보다 작으면 음수, 평균보다 크면 양수로 나타난다. 이때 계산되는 음수와 양수의 크기는 그 feature의 표준 편차에 의해 결정된다. 
## 5번

**Local Minima와 Global Minima에 대해 설명해주세요.**

![](https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Extrema_example_original.svg/220px-Extrema_example_original.svg.png)

cost function 함수의 최소값을 취하는 지점을 `Global Minima`라고 한다. 그러나 Cost function이 최소값이 되는 구간을 찾기 위해 경사하강법과 같은 최적화 알고리즘을 사용하다보면 함수가 다른 지점에서 최소값을 찾은것처럼 착각 할 수 있습니다. Cost function이 함수의 최솟값이라고 착각 할 수 있는 지점을 `Locla Minima`라고 합니다. 

## 6번

**차원의 저주에 대해 설명해주세요**

차원의 저주란 데이터 학습을 위해 차원이 증가하면서 학습데이터 수가 차원의 수보다 적어져 **성능이 저하되는 현상이다.**  
차원이 증가할 수록 개별 차원 내 학습할 데이터 수가 **적어지는(sparse) 현상 발생**  

차원의 저주를 해결 하기 위해서는 차원을 줄이거나 데이터를 많이 휙득하면 된다.  

## 7번

dimension reduction기법으로 보통 어떤 것들이 있나요?

## 8번
PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 
제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?

## 9번
LSA, LDA, SVD 등의 약자들이 어떤 뜻이고 서로 어떤 관계를 가지는지 설명할 수 있나요?

## 10번
Markov Chain을 고등학생에게 설명하려면 어떤 방식이 제일 좋을까요?

## 11번
텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?

## 12번
SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? 거기서 어떤 장점이 발생했나요?

## 13번
다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요.

## 14번
Association Rule의 Support, Confidence, Lift에 대해 설명해주세요.

## 15번
최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?

## 16번
머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?

## 17번
인공신경망(deep learning이전의 전통적인)이 가지는 일반적인 문제점은 무엇일까요?

## 18번
지금 나오고 있는 deep learning 계열의 혁신의 근간은 무엇이라고 생각하시나요?
ROC 커브에 대해 설명해주실 수 있으신가요?

## 19번
여러분이 서버를 100대 가지고 있습니다. 이때 인공신경망보다 Random Forest를 써야하는 이유는 뭘까요?

## 20번
K-means의 대표적 의미론적 단점은 무엇인가요? (계산량 많다는것 말고)

## 21번
**L1, L2 정규화에 대해 설명해주세요**

결론부터 이야기하면 `L1 Regularization` 과 `L2 Regularization`은 Overfitting(과적합)을 막기 위해 사용 됩니다.

위 두 개념을 이해하기 위해서는 필요한 개념들을 먼저 설명하고 마지막에 
`L1 Regularization` 과 `L2 Regularization` 설명할 예정입니다. 

순서는 다음과 같고 이 글은 ['light-tree 티스토리'](https://light-tree.tistory.com/125)를 참고하여 작성 되었습니다.

1. Norm
2. L1 Norm과 L2 Norm
3. L1 Loss 와 L2 Loss 

4. L1 Regularization
5. L2 Regularization
6. L1 Regularization, L2 Regularization 의 차이와 선택 기준

### Norm
Norm은 벡터의 크기(혹은 길이)를 측정하는 방법(혹은 함수) 입니다.  두 벡터 사이의 거리를 측정하는 방법이기도 합니다. 
![](https://wikimedia.org/api/rest_v1/media/math/render/svg/53a5615d02f7a03013e22bd4adf055cdbe4a303c)
* 여기서 p는 Norm의 차수를 의미합니다. p = 1이면 L1 Norm이고, p = 2 이면 L2 Norm 입니다.
* N은 해당 벡터의 원소 수 입니다.


### L1 Norm 과 L2 Norm

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FTWoq0%2FbtqyeIS3zkS%2FdM9k9mLKifZvlidw4GftN0%2Fimg.png)

검정색 두 점사이의 L1 Norm은 빨간색, 파란색, 노란색 선으로 표현 될 수 있고, L2 Norm은 오직 초록색 선으로만 표현 될 수 있습니다. L1 Norm은 여러가지 path를 가지지만 L2 Norm은 Unique shortest path를 가집니다.  
예를 들어 p = (1,0), q = (0,0) 일 때 L1 Norm = 1, L2 Norm = 1로 값은 같지만 여전히 Unique shortest path 라고 할 수 있습니다. 

### L1 loss 와 L2 loss

- `L1-loss`는 **타겟값과 예측값의 차를 절대 값으로 구한것** 입니다.  
- `L2-loss`는 **타겟값과 에측값의 차의 제곱으로 구한 것** 입니다.  
    
L2 Loss는 직관적으로 오차의 제곱을 더하기 때문에 Outlier에 더 큰 영향을 받습니다. "L1 Loss가 L2 Loss에 비해 Outlier에 대하여 더 Robust(덜 민감 혹은 둔감)하다."라고 표현 할 수 있습니다.  
Outlier가 적당히 무시되길 원한다면 L1 Loss를 사용하고, Outlier의 등장에 신경써야 하는 경우라면 L2 Loss를 사용하는 것이 좋습니다.   
L1  Loss는 0 인 지점에서 미분이 불가능하다는 단점 또한 가지고 있습니다.

### L1 Regularization 

[](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkClJn%2FbtqLA20hMN9%2FKR9d27A0SkCKkad91TPujk%2Fimg.png)   


L1 Regularization 은 위 수식처럼 표현 할 수 있습니다. L1 Regularization의 개념에서 가장 중요한 것은 cost function에 가중치의 절대값을 더해준다는 것 입니다.  

기존의 cost function에 가중치의 크기가 포함되면서 가중치가 너무 크지 않은 방향으로 학습 되도록 합니다. 이때 λ는 learning rate 같은 상수로 0에 가까울 수록 정규화의 효과는 없어집니다.    

L1 Regularization을 사용하는 Regression model 을 Least Absolute Shrinkage and Selection Operater(Lasso) Regression 이라고 부릅니다.  

### L2 Regularization

[](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fvwncr%2FbtqLzYD49Ef%2F4YyPJV8WMyfxLHPS3nQLq1%2Fimg.png)  

기존의 Cost Function에 가중치의 제곱을 포함하여 더함으로써 L1 Regularization과 마찬가지로 가중치가 너무 크지 않은 방향으로 학습되게 됩니다. 이를 Weight decay 라고도 합니다.  

L2 Regularzation을 사용하는 Regression model을 Ridge Regression 라고 부릅니다.  

### L1 Regularization, L2 Regularization의 차이와 선택 기준

먼저 Regularization의 의미를 되새겨 보면, 가중치 W가 작아지도록 학습한 다는 것은 결국 Local nosie에 영향을 덜 받도록 하겠다는 것이며 이는 Outlier의 영향을 더 적게 받도록 하겠다는 것입니다. 

> a = (0.3, -0.3, 0.4)    
> b = (0.5, -0.5, 0)

벡터 a와 b에 대해서 L1 Norm과 L2 Norm을 계산하면 각각 아래와 같습니다.

> ||a||_1 = |0.3| + |-0.3| + |0.4| = 1  
> ||b||_1 = |0.5| + |-0.5| + |0| = 1
  
> ||a||_2 = 0.583095
> ||b|_2 = 0.707107

L2 Norm은 각각의 벡터에 대해 항상 Unique 한 값을 내지만, L1 Norm은 경우에 따라 특정 Feature(벡터의 요소) 없이도 같은 값을 낼 수 있다는 뜻입니다. 

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FTWoq0%2FbtqyeIS3zkS%2FdM9k9mLKifZvlidw4GftN0%2Fimg.png)  


L1 Norm은 파란색 선 대신 빨간색 선을 사용하여 특정 Feature를 0으로 처리하는 것이 가능하다고 이해할 수 있습니다. 다시 말하자면 **L1 Norm은 Feature selection 이 가능** 하고 이런 특징이 L1 Regularization에 동일하게 적용 될 수 있는 것입니다. 이러한 특징 때문에 L1은 Sparse model(coding)에 적합합니다. L1 Norm의 이러한 특징 때문에 convex optimization에 유용하게 쓰인다고 합니다.



## 22번

XGBoost을 아시나요? 왜 이 모델이 캐글에서 유명할까요?

## 23번
앙상블 방법엔 어떤 것들이 있나요?

## 24번
feature vector란 무엇일까요?

## 25번
좋은 모델의 정의는 무엇일까요?

## 26번
50개의 작은 의사결정 나무는 큰 의사결정 나무보다 괜찮을까요? 왜 그렇게 생각하나요?

## 27번
스팸 필터에 로지스틱 리그레션을 많이 사용하는 이유는 무엇일까요?

## 28번
OLS(ordinary least squre) regression의 공식은 무엇인가요?